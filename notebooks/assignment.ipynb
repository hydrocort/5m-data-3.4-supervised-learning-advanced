{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c98237",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1.  **Regularization**:\n",
    "\n",
    "    - Use the `diabetes` dataset from `sklearn.datasets`.\n",
    "    - Compare the performance (Mean Squared Error) of `LinearRegression`, `Ridge`, and `Lasso` models.\n",
    "    - Tune the `alpha` parameter for `Ridge` and `Lasso` using `GridSearchCV` with cross-validation to find the optimal regularization strength.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.datasets import load_diabetes\n",
    "\n",
    "    # Load the diabetes dataset\n",
    "    diabetes = load_diabetes()\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d626c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset Description ---\n",
      "Full dataset description:\n",
      ".. _diabetes_dataset:\n",
      "\n",
      "Diabetes dataset\n",
      "----------------\n",
      "\n",
      "Ten baseline variables, age, sex, body mass index, average blood\n",
      "pressure, and six blood serum measurements were obtained for each of n =\n",
      "442 diabetes patients, as well as the response of interest, a\n",
      "quantitative measure of disease progression one year after baseline.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "  :Number of Instances: 442\n",
      "\n",
      "  :Number of Attributes: First 10 columns are numeric predictive values\n",
      "\n",
      "  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\n",
      "\n",
      "  :Attribute Information:\n",
      "      - age     age in years\n",
      "      - sex\n",
      "      - bmi     body mass index\n",
      "      - bp      average blood pressure\n",
      "      - s1      tc, total serum cholesterol\n",
      "      - s2      ldl, low-density lipoproteins\n",
      "      - s3      hdl, high-density lipoproteins\n",
      "      - s4      tch, total cholesterol / HDL\n",
      "      - s5      ltg, possibly log of serum triglycerides level\n",
      "      - s6      glu, blood sugar level\n",
      "\n",
      "Note: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times the square root of `n_samples` (i.e. the sum of squares of each column totals 1).\n",
      "\n",
      "Source URL:\n",
      "https://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\n",
      "\n",
      "For more information see:\n",
      "Bradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\n",
      "(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "\n",
    "# Dataset description\n",
    "print(\"\\n--- Dataset Description ---\")\n",
    "print(\"Full dataset description:\")\n",
    "print(diabetes.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54b1b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATASET EXPLORATION ===\n",
      "\n",
      "--- Target Variable ---\n",
      "Target represents: Disease progression after one year\n",
      "Target type: <class 'numpy.ndarray'>\n",
      "Target shape: (442,)\n",
      "Target statistics:\n",
      "  Min: 25.00\n",
      "  Max: 346.00\n",
      "  Mean: 152.13\n",
      "  Std: 77.01\n",
      "  Median: 140.50\n",
      "\n",
      "--- Features ---\n",
      "Number of features: 10\n",
      "Feature names: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n",
      "Feature matrix shape: (442, 10)\n",
      "Feature matrix type: <class 'numpy.ndarray'>\n",
      "\n",
      "Feature statistics:\n",
      "           age      sex      bmi       bp       s1       s2       s3       s4  \\\n",
      "count  442.000  442.000  442.000  442.000  442.000  442.000  442.000  442.000   \n",
      "mean    -0.000    0.000   -0.000   -0.000   -0.000    0.000   -0.000   -0.000   \n",
      "std      0.048    0.048    0.048    0.048    0.048    0.048    0.048    0.048   \n",
      "min     -0.107   -0.045   -0.090   -0.112   -0.127   -0.116   -0.102   -0.076   \n",
      "25%     -0.037   -0.045   -0.034   -0.037   -0.034   -0.030   -0.035   -0.039   \n",
      "50%      0.005   -0.045   -0.007   -0.006   -0.004   -0.004   -0.007   -0.003   \n",
      "75%      0.038    0.051    0.031    0.036    0.028    0.030    0.029    0.034   \n",
      "max      0.111    0.051    0.171    0.132    0.154    0.199    0.181    0.185   \n",
      "\n",
      "            s5       s6  \n",
      "count  442.000  442.000  \n",
      "mean     0.000    0.000  \n",
      "std      0.048    0.048  \n",
      "min     -0.126   -0.138  \n",
      "25%     -0.033   -0.033  \n",
      "50%     -0.002   -0.001  \n",
      "75%      0.032    0.028  \n",
      "max      0.134    0.136  \n",
      "\n",
      "First 5 rows of features:\n",
      "        age       sex       bmi        bp        s1        s2        s3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         s4        s5        s6  \n",
      "0 -0.002592  0.019907 -0.017646  \n",
      "1 -0.039493 -0.068332 -0.092204  \n",
      "2 -0.002592  0.002861 -0.025930  \n",
      "3  0.034309  0.022688 -0.009362  \n",
      "4 -0.002592 -0.031988 -0.046641  \n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Dataset exploration - Features and Target information\n",
    "print(\"\\n=== DATASET EXPLORATION ===\")\n",
    "\n",
    "# Target variable information\n",
    "print(\"\\n--- Target Variable ---\")\n",
    "print(\"Target represents: Disease progression after one year\")\n",
    "print(\"Target type:\", type(y))\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Target statistics:\")\n",
    "print(f\"  Min: {y.min():.2f}\")\n",
    "print(f\"  Max: {y.max():.2f}\")\n",
    "print(f\"  Mean: {y.mean():.2f}\")\n",
    "print(f\"  Std: {y.std():.2f}\")\n",
    "print(f\"  Median: {np.median(y):.2f}\")\n",
    "\n",
    "# Feature information\n",
    "print(\"\\n--- Features ---\")\n",
    "print(\"Number of features:\", len(diabetes.feature_names))\n",
    "print(\"Feature names:\", diabetes.feature_names)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Feature matrix type:\", type(X))\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "features_df = pd.DataFrame(X, columns=diabetes.feature_names)\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(features_df.describe().round(3))\n",
    "\n",
    "print(\"\\nFirst 5 rows of features:\")\n",
    "print(features_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sf8rhvurdon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 3424.26\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression (baseline)\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(X_train, y_train)\n",
    "\n",
    "linear_preds = linear_reg.predict(X_test)\n",
    "linear_mse = mean_squared_error(y_test, linear_preds)\n",
    "\n",
    "print(f'Linear Regression MSE: {linear_mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pqvlbbwmj6m",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - Best alpha: 0.1\n",
      "Ridge - Best CV score: 2886.90\n",
      "Ridge Regression MSE: 3372.61\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression with hyperparameter tuning\n",
    "ridge_param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0]}\n",
    "\n",
    "ridge_grid_search = GridSearchCV(\n",
    "    estimator=Ridge(random_state=0), \n",
    "    param_grid=ridge_param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Ridge model\n",
    "best_ridge = ridge_grid_search.best_estimator_\n",
    "ridge_preds = best_ridge.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_preds)\n",
    "\n",
    "print(f\"Ridge - Best alpha: {ridge_grid_search.best_params_['alpha']}\")\n",
    "print(f\"Ridge - Best CV score: {-ridge_grid_search.best_score_:.2f}\")\n",
    "print(f'Ridge Regression MSE: {ridge_mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "gif4mpscf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso - Best alpha: 0.01\n",
      "Lasso - Best CV score: 2872.37\n",
      "Lasso Regression MSE: 3445.81\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression with hyperparameter tuning\n",
    "lasso_param_grid = {'alpha': [0.01, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0]}\n",
    "\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=Lasso(random_state=0), \n",
    "    param_grid=lasso_param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lasso_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Lasso model\n",
    "best_lasso = lasso_grid_search.best_estimator_\n",
    "lasso_preds = best_lasso.predict(X_test)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_preds)\n",
    "\n",
    "print(f\"Lasso - Best alpha: {lasso_grid_search.best_params_['alpha']}\")\n",
    "print(f\"Lasso - Best CV score: {-lasso_grid_search.best_score_:.2f}\")\n",
    "print(f'Lasso Regression MSE: {lasso_mse:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hmjpv9rktfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Regularization Results Comparison ===\n",
      "            Model         MSE Best_Alpha\n",
      "Linear Regression 3424.259334        N/A\n",
      " Ridge Regression 3372.612250        0.1\n",
      " Lasso Regression 3445.806809       0.01\n",
      "\n",
      "=== Lasso Feature Selection ===\n",
      "Number of non-zero coefficients in Lasso: 9 out of 10\n",
      "Number of features zeroed out: 1\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Ridge Regression', 'Lasso Regression'],\n",
    "    'MSE': [linear_mse, ridge_mse, lasso_mse],\n",
    "    'Best_Alpha': ['N/A', ridge_grid_search.best_params_['alpha'], lasso_grid_search.best_params_['alpha']]\n",
    "})\n",
    "\n",
    "print(\"=== Regularization Results Comparison ===\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Show feature coefficients for Lasso (feature selection effect)\n",
    "print(f\"\\n=== Lasso Feature Selection ===\")\n",
    "print(f\"Number of non-zero coefficients in Lasso: {sum(best_lasso.coef_ != 0)} out of {len(best_lasso.coef_)}\")\n",
    "print(f\"Number of features zeroed out: {sum(best_lasso.coef_ == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ab6cc",
   "metadata": {},
   "source": [
    "2.  **Ensemble Methods**:\n",
    "\n",
    "    - Use the `breast_cancer` dataset from `sklearn.datasets`.\n",
    "    - Compare the performance (F1 Score and AUC) of `DecisionTreeClassifier`, `RandomForestClassifier`, and `GradientBoostingClassifier`.\n",
    "    - Tune the hyperparameters of each classifier using `GridSearchCV` with cross-validation.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "    # Load the breast cancer dataset\n",
    "    breast_cancer = load_breast_cancer()\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86aca8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset Description ---\n",
      "Full dataset description:\n",
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Ensemble Methods\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, roc_curve, auc, accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Dataset description\n",
    "print(\"\\n--- Dataset Description ---\")\n",
    "print(\"Full dataset description:\")\n",
    "print(breast_cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4ae358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DATASET EXPLORATION ===\n",
      "\n",
      "--- Target Variable ---\n",
      "Target names: ['malignant' 'benign']\n",
      "Target classes and their encoded values:\n",
      "  0: malignant\n",
      "  1: benign\n",
      "Target type: <class 'numpy.ndarray'>\n",
      "Target shape: (569,)\n",
      "Target sample values: [0 0 0 0 0 0 0 0 0 0]\n",
      "Class distribution: {0: 212, 1: 357}\n",
      "\n",
      "--- Features ---\n",
      "Number of features: 30\n",
      "Feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Feature matrix shape: (569, 30)\n",
      "Feature matrix type: <class 'numpy.ndarray'>\n",
      "\n",
      "Feature statistics:\n",
      "       mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "count      569.000       569.000         569.000    569.000          569.000   \n",
      "mean        14.127        19.290          91.969    654.889            0.096   \n",
      "std          3.524         4.301          24.299    351.914            0.014   \n",
      "min          6.981         9.710          43.790    143.500            0.053   \n",
      "25%         11.700        16.170          75.170    420.300            0.086   \n",
      "50%         13.370        18.840          86.240    551.100            0.096   \n",
      "75%         15.780        21.800         104.100    782.700            0.105   \n",
      "max         28.110        39.280         188.500   2501.000            0.163   \n",
      "\n",
      "       mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "count           569.000         569.000              569.000        569.000   \n",
      "mean              0.104           0.089                0.049          0.181   \n",
      "std               0.053           0.080                0.039          0.027   \n",
      "min               0.019           0.000                0.000          0.106   \n",
      "25%               0.065           0.030                0.020          0.162   \n",
      "50%               0.093           0.062                0.034          0.179   \n",
      "75%               0.130           0.131                0.074          0.196   \n",
      "max               0.345           0.427                0.201          0.304   \n",
      "\n",
      "       mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "count                 569.000  ...       569.000        569.000   \n",
      "mean                    0.063  ...        16.269         25.677   \n",
      "std                     0.007  ...         4.833          6.146   \n",
      "min                     0.050  ...         7.930         12.020   \n",
      "25%                     0.058  ...        13.010         21.080   \n",
      "50%                     0.062  ...        14.970         25.410   \n",
      "75%                     0.066  ...        18.790         29.720   \n",
      "max                     0.097  ...        36.040         49.540   \n",
      "\n",
      "       worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "count          569.000     569.000           569.000            569.000   \n",
      "mean           107.261     880.583             0.132              0.254   \n",
      "std             33.603     569.357             0.023              0.157   \n",
      "min             50.410     185.200             0.071              0.027   \n",
      "25%             84.110     515.300             0.117              0.147   \n",
      "50%             97.660     686.500             0.131              0.212   \n",
      "75%            125.400    1084.000             0.146              0.339   \n",
      "max            251.200    4254.000             0.223              1.058   \n",
      "\n",
      "       worst concavity  worst concave points  worst symmetry  \\\n",
      "count          569.000               569.000         569.000   \n",
      "mean             0.272                 0.115           0.290   \n",
      "std              0.209                 0.066           0.062   \n",
      "min              0.000                 0.000           0.156   \n",
      "25%              0.114                 0.065           0.250   \n",
      "50%              0.227                 0.100           0.282   \n",
      "75%              0.383                 0.161           0.318   \n",
      "max              1.252                 0.291           0.664   \n",
      "\n",
      "       worst fractal dimension  \n",
      "count                  569.000  \n",
      "mean                     0.084  \n",
      "std                      0.018  \n",
      "min                      0.055  \n",
      "25%                      0.071  \n",
      "50%                      0.080  \n",
      "75%                      0.092  \n",
      "max                      0.208  \n",
      "\n",
      "[8 rows x 30 columns]\n",
      "\n",
      "First 5 rows of features:\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Dataset exploration - Features and Target information\n",
    "print(\"\\n=== DATASET EXPLORATION ===\")\n",
    "\n",
    "# Target variable information\n",
    "print(\"\\n--- Target Variable ---\")\n",
    "if hasattr(breast_cancer, 'target_names'):\n",
    "    print(\"Target names:\", breast_cancer.target_names)\n",
    "    print(\"Target classes and their encoded values:\")\n",
    "    for idx, name in enumerate(breast_cancer.target_names):\n",
    "        print(f\"  {idx}: {name}\")\n",
    "else:\n",
    "    print(\"No target_names attribute. Check DESCR for details.\")\n",
    "print(\"Target type:\", type(y))\n",
    "print(\"Target shape:\", y.shape)\n",
    "print(\"Target sample values:\", y[:10])\n",
    "print(\"Class distribution:\", pd.Series(y).value_counts().sort_index().to_dict())\n",
    "\n",
    "# Feature information\n",
    "print(\"\\n--- Features ---\")\n",
    "print(\"Number of features:\", len(breast_cancer.feature_names))\n",
    "print(\"Feature names:\", breast_cancer.feature_names)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Feature matrix type:\", type(X))\n",
    "\n",
    "features_df = pd.DataFrame(X, columns=breast_cancer.feature_names)\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(features_df.describe().round(3))\n",
    "\n",
    "print(\"\\nFirst 5 rows of features:\")\n",
    "print(features_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01vgt2udb6u2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Best params: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Decision Tree - Best CV F1: 0.9438\n",
      "Decision Tree - Test F1: 0.9697\n",
      "Decision Tree - Test AUC: 0.9725\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Decision Tree Classifier with hyperparameter tuning\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 3, 5, 7, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "dt_grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=0), \n",
    "    param_grid=dt_param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Decision Tree model\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "dt_preds = best_dt.predict(X_test)\n",
    "dt_proba = best_dt.predict_proba(X_test)[:, 1]\n",
    "\n",
    "dt_f1 = f1_score(y_test, dt_preds)\n",
    "dt_fpr, dt_tpr, _ = roc_curve(y_test, dt_proba)\n",
    "dt_auc = auc(dt_fpr, dt_tpr)\n",
    "\n",
    "print(f\"Decision Tree - Best params: {dt_grid_search.best_params_}\")\n",
    "print(f\"Decision Tree - Best CV F1: {dt_grid_search.best_score_:.4f}\")\n",
    "print(f'Decision Tree - Test F1: {dt_f1:.4f}')\n",
    "print(f'Decision Tree - Test AUC: {dt_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "iea6xndod6i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Best params: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest - Best CV F1: 0.9663\n",
      "Random Forest - Test F1: 0.9697\n",
      "Random Forest - Test AUC: 0.9965\n"
     ]
    }
   ],
   "source": [
    "# 2.2 Random Forest Classifier with hyperparameter tuning\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=0), \n",
    "    param_grid=rf_param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "rf_preds = best_rf.predict(X_test)\n",
    "rf_proba = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_f1 = f1_score(y_test, rf_preds)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_proba)\n",
    "rf_auc = auc(rf_fpr, rf_tpr)\n",
    "\n",
    "print(f\"Random Forest - Best params: {rf_grid_search.best_params_}\")\n",
    "print(f\"Random Forest - Best CV F1: {rf_grid_search.best_score_:.4f}\")\n",
    "print(f'Random Forest - Test F1: {rf_f1:.4f}')\n",
    "print(f'Random Forest - Test AUC: {rf_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8i7xlf51lzs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Best params: {'learning_rate': 0.2, 'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Gradient Boosting - Best CV F1: 0.9781\n",
      "Gradient Boosting - Test F1: 0.9706\n",
      "Gradient Boosting - Test AUC: 0.9975\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Gradient Boosting Classifier with hyperparameter tuning\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "gb_grid_search = GridSearchCV(\n",
    "    estimator=GradientBoostingClassifier(random_state=0), \n",
    "    param_grid=gb_param_grid, \n",
    "    cv=5, \n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Gradient Boosting model\n",
    "best_gb = gb_grid_search.best_estimator_\n",
    "gb_preds = best_gb.predict(X_test)\n",
    "gb_proba = best_gb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "gb_f1 = f1_score(y_test, gb_preds)\n",
    "gb_fpr, gb_tpr, _ = roc_curve(y_test, gb_proba)\n",
    "gb_auc = auc(gb_fpr, gb_tpr)\n",
    "\n",
    "print(f\"Gradient Boosting - Best params: {gb_grid_search.best_params_}\")\n",
    "print(f\"Gradient Boosting - Best CV F1: {gb_grid_search.best_score_:.4f}\")\n",
    "print(f'Gradient Boosting - Test F1: {gb_f1:.4f}')\n",
    "print(f'Gradient Boosting - Test AUC: {gb_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "phzhi5dtin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ensemble Methods Results Comparison ===\n",
      "            Model  Test_F1_Score  Test_AUC  CV_F1_Score\n",
      "    Decision Tree       0.969697  0.972531     0.943763\n",
      "    Random Forest       0.969697  0.996507     0.966261\n",
      "Gradient Boosting       0.970588  0.997460     0.978064\n",
      "\n",
      "=== Additional Metrics ===\n",
      "Decision Tree: Accuracy=0.9649, Precision=0.9846, Recall=0.9552\n",
      "Random Forest: Accuracy=0.9649, Precision=0.9846, Recall=0.9552\n",
      "Gradient Boosting: Accuracy=0.9649, Precision=0.9565, Recall=0.9851\n"
     ]
    }
   ],
   "source": [
    "# 2.4 Compare ensemble methods results\n",
    "ensemble_results_df = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Random Forest', 'Gradient Boosting'],\n",
    "    'Test_F1_Score': [dt_f1, rf_f1, gb_f1],\n",
    "    'Test_AUC': [dt_auc, rf_auc, gb_auc],\n",
    "    'CV_F1_Score': [dt_grid_search.best_score_, rf_grid_search.best_score_, gb_grid_search.best_score_]\n",
    "})\n",
    "\n",
    "print(\"=== Ensemble Methods Results Comparison ===\")\n",
    "print(ensemble_results_df.to_string(index=False))\n",
    "\n",
    "# Additional metrics for completeness\n",
    "print(\"\\n=== Additional Metrics ===\")\n",
    "for name, preds in [('Decision Tree', dt_preds), ('Random Forest', rf_preds), ('Gradient Boosting', gb_preds)]:\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds)\n",
    "    recall = recall_score(y_test, preds)\n",
    "    print(f\"{name}: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
